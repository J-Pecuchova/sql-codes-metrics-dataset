{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8656e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de497a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TG</th>\n",
       "      <th>Student</th>\n",
       "      <th>Model</th>\n",
       "      <th>Variant</th>\n",
       "      <th>X</th>\n",
       "      <th>AXC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>ChatGPT5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CREATE OR REPLACE TABLE retail (\\n    invoice_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>ChatGPT5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CREATE OR REPLACE TABLE retail (\\n    invoice_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>ChatGPT5.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>CREATE OR REPLACE TABLE retail (\\n    invoice_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>ChatGPT5.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CREATE OR REPLACE TABLE retail (\\n  invoice_no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>-1</td>\n",
       "      <td>ChatGPT5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CREATE OR REPLACE TABLE games (\\n    id       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID TG  Student       Model  Variant  X  \\\n",
       "0   1  A       -1  ChatGPT5.2        0  1   \n",
       "1   2  A       -1  ChatGPT5.2        1  1   \n",
       "2   3  A       -1  ChatGPT5.2        2  1   \n",
       "3   4  A       -1  ChatGPT5.2        3  1   \n",
       "4   5  B       -1  ChatGPT5.2        0  1   \n",
       "\n",
       "                                                 AXC  \n",
       "0  CREATE OR REPLACE TABLE retail (\\n    invoice_...  \n",
       "1  CREATE OR REPLACE TABLE retail (\\n    invoice_...  \n",
       "2  CREATE OR REPLACE TABLE retail (\\n    invoice_...  \n",
       "3  CREATE OR REPLACE TABLE retail (\\n  invoice_no...  \n",
       "4  CREATE OR REPLACE TABLE games (\\n    id       ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SQL_codes_dataset.csv', sep=';', decimal=',', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9a6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_OPERATORS = {'SELECT', 'FROM', 'WHERE', 'GROUP', 'BY', 'ORDER', 'HAVING', 'LIMIT', 'OFFSET', 'DISTINCT', 'AS', 'ON', 'USING', 'INSERT', 'UPDATE', 'DELETE', 'INTO', 'VALUES', 'SET', 'CREATE', 'ALTER', 'DROP', 'TABLE', 'VIEW', 'INDEX'}\n",
    "SQL_JOIN_KEYWORDS = {'JOIN', 'INNER', 'LEFT', 'RIGHT', 'FULL', 'OUTER'} # not present in the examined dataset\n",
    "SQL_LOGICAL_OPERATORS = {'AND', 'OR', 'NOT', 'IN', 'EXISTS', 'BETWEEN', 'LIKE', 'ILIKE', 'IS', 'NULL', 'TRUE', 'FALSE', 'ALL', 'ANY', 'SOME'}\n",
    "SQL_COMPARISON_OPERATORS = {'=', '<>', '!=', '<', '>', '<=', '>='}\n",
    "SQL_CONDITIONAL_KEYWORDS = {'CASE', 'WHEN', 'THEN', 'ELSE', 'END', 'IF', 'IFF'}\n",
    "SQL_WINDOW_KEYWORDS = {'OVER', 'PARTITION', 'ROWS', 'RANGE', 'UNBOUNDED', 'PRECEDING', 'FOLLOWING', 'CURRENT', 'ROW'}\n",
    "SQL_AGGREGATE_FUNCTIONS = {'SUM', 'COUNT', 'AVG', 'MIN', 'MAX', 'ARRAY_AGG', 'MEDIAN'}\n",
    "SQL_WINDOW_FUNCTIONS = {'ROW_NUMBER', 'RANK', 'DENSE_RANK', 'NTILE', 'LAG', 'LEAD'}\n",
    "\n",
    "ALL_SQL_OPERATORS = (SQL_OPERATORS | SQL_JOIN_KEYWORDS | SQL_LOGICAL_OPERATORS | SQL_CONDITIONAL_KEYWORDS | SQL_WINDOW_KEYWORDS | SQL_AGGREGATE_FUNCTIONS | SQL_WINDOW_FUNCTIONS | SQL_COMPARISON_OPERATORS |\n",
    "  {'(', ')', ',', '.', ';', '*', '+', '-', '/', '%'}\n",
    ")\n",
    "\n",
    "# Weights for different SQL constructs \n",
    "SQL_COMMAND_WEIGHTS = {\n",
    "  'SELECT': 1.0,\n",
    "  'JOIN': 2.5, # not present in the examined dataset\n",
    "  'SUBQUERY': 3.0,\n",
    "  'WINDOW': 2.5,\n",
    "  'AGGREGATE': 1.5,\n",
    "  'CASE': 2.0, # not present in the examined dataset\n",
    "  'CTE': 2.0,\n",
    "  'UNION': 1.5 # not present in the examined dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3b3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(sql):\n",
    "  sql = re.sub(r'--.*$', '', sql, flags=re.MULTILINE)\n",
    "  sql = re.sub(r'/\\*.*?\\*/', '', sql, flags=re.DOTALL)\n",
    "  return sql\n",
    "\n",
    "def tokenize(sql):\n",
    "  sql = remove_comments(sql)\n",
    "  string_pattern = re.compile(r\"'[^']*'|\\\"[^\\\"]*\\\"\")\n",
    "  symbol_pattern = re.compile(r'<>|!=|<=|>=|::|\\|\\||[(),.*+\\-/%;=<>]')\n",
    "  strings = string_pattern.findall(sql)\n",
    "  sql_no_strings = string_pattern.sub(' __STRING__ ', sql)\n",
    "  parts = symbol_pattern.split(sql_no_strings)\n",
    "  symbols = symbol_pattern.findall(sql_no_strings)\n",
    "    \n",
    "  result = []\n",
    "  for i, part in enumerate(parts):\n",
    "    words = part.split()\n",
    "    result.extend(words)\n",
    "    if i<len(symbols):\n",
    "      result.append(symbols[i])\n",
    "    \n",
    "  string_idx = 0\n",
    "  for i, token in enumerate(result):\n",
    "    if token == '__STRING__' and string_idx<len(strings):\n",
    "      result[i] = strings[string_idx]\n",
    "      string_idx += 1\n",
    "    \n",
    "  return [t for t in result if t.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3980dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_metrics(sql):\n",
    "  lines = sql.split('\\n')\n",
    "  tokens = tokenize(sql)\n",
    "  return {\n",
    "    'lines_of_code': len(lines),\n",
    "    'character_length': len(sql),\n",
    "    'token_count': len(tokens)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d4fb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_tokens(tokens):\n",
    "  number_pattern = re.compile(r'\\b\\d+\\.?\\d*\\b')\n",
    "  operators = []\n",
    "  operands = []\n",
    "  for token in tokens:\n",
    "    upper_token = token.upper()\n",
    "    if upper_token in ALL_SQL_OPERATORS or token in ALL_SQL_OPERATORS:\n",
    "      operators.append(upper_token if upper_token in ALL_SQL_OPERATORS else token)\n",
    "    elif token.startswith(\"'\") or token.startswith('\"'):\n",
    "      operands.append(token)\n",
    "    elif number_pattern.fullmatch(token):\n",
    "      operands.append(token)\n",
    "    else:\n",
    "      operands.append(token.lower())\n",
    "    \n",
    "  return {\n",
    "    'unique_operators': set(operators),\n",
    "    'unique_operands': set(operands),\n",
    "    'total_operators': len(operators),\n",
    "    'total_operands': len(operands)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1074c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halstead_metrics(sql):\n",
    "  tokens = tokenize(sql)\n",
    "  divided_tokens = divide_tokens(tokens)\n",
    "  n1 = len(divided_tokens['unique_operators'])\n",
    "  n2 = len(divided_tokens['unique_operands'])\n",
    "  N1 = divided_tokens['total_operators']\n",
    "  N2 = divided_tokens['total_operands']\n",
    "  \n",
    "  vocabulary = n1+n2\n",
    "  program_length = N1+N2\n",
    "  volume = program_length*math.log2(vocabulary) if vocabulary>1 else 0\n",
    "  difficulty = (n1/2)*(N2/n2) if n1>0 and n2>0 else 0\n",
    "  effort = difficulty*volume\n",
    "  time_to_program = effort/18 \n",
    "    \n",
    "  return {\n",
    "    'n1_distinct_operators': n1,\n",
    "    'n2_distinct_operands': n2,\n",
    "    'N1_total_operators': N1,\n",
    "    'N2_total_operands': N2,\n",
    "    'vocabulary': vocabulary,\n",
    "    'program_length': program_length,\n",
    "    'volume': round(volume, 2),\n",
    "    'difficulty': round(difficulty, 2),\n",
    "    'effort': round(effort, 2),\n",
    "    'time_to_program': round(time_to_program, 2)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4bed8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_constructs(sql):\n",
    "  sql_upper = sql.upper()\n",
    "  return {\n",
    "    'subquery_count': max(0, len(re.findall(r'\\bSELECT\\b', sql_upper))-1),\n",
    "    'window_function_count': len(re.findall(r'\\bOVER\\s*\\(', sql_upper)),\n",
    "    'aggregate_function_count': sum(len(re.findall(rf'\\b{func}\\s*\\(', sql_upper)) for func in SQL_AGGREGATE_FUNCTIONS),\n",
    "    'cte_count': len(re.findall(r'\\bWITH\\b', sql_upper))\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ead8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesting_depth(sql):\n",
    "  max_depth = 0\n",
    "  current_depth = 0\n",
    "  for char in sql:\n",
    "    if char == '(':\n",
    "      current_depth += 1\n",
    "      max_depth = max(max_depth, current_depth)\n",
    "    elif char == ')':\n",
    "      current_depth = max(0, current_depth-1)\n",
    "  return max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c81b2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cognitive_complexity(sql):\n",
    "  sql_upper = sql.upper()\n",
    "  complexity = 0\n",
    "  complexity += len(re.findall(r'\\(\\s*SELECT\\b', sql_upper))*3\n",
    "  complexity += len(re.findall(r'\\bAND\\b', sql_upper))*1\n",
    "  complexity += len(re.findall(r'\\bOR\\b', sql_upper))*1\n",
    "  complexity += len(re.findall(r'\\bOVER\\s*\\(', sql_upper))*2\n",
    "  max_depth = nesting_depth(sql)\n",
    "  if max_depth>2:\n",
    "    complexity += (max_depth-2)*2\n",
    "  return complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aa3206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cognitive_metrics(sql):\n",
    "  return {\n",
    "    'max_nesting_depth': nesting_depth(sql),\n",
    "    'cognitive_complexity': cognitive_complexity(sql),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd07017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tables(sql):\n",
    "  sql_upper = sql.upper()\n",
    "  from_count = len(re.findall(r'\\bFROM\\b', sql_upper))\n",
    "  join_count = len(re.findall(r'\\bJOIN\\b', sql_upper))\n",
    "  return from_count + join_count\n",
    "\n",
    "def count_columns(tokens):\n",
    "  all_keywords = SQL_OPERATORS | SQL_JOIN_KEYWORDS | SQL_LOGICAL_OPERATORS | SQL_AGGREGATE_FUNCTIONS | SQL_WINDOW_FUNCTIONS | SQL_CONDITIONAL_KEYWORDS | SQL_WINDOW_KEYWORDS\n",
    "  identifier_pattern = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_]*$')\n",
    "  count = 0\n",
    "  for token in tokens:\n",
    "    if identifier_pattern.match(token) and token.upper() not in all_keywords:\n",
    "      count += 1\n",
    "  return count\n",
    "\n",
    "def count_expressions(sql):\n",
    "  sql_upper = sql.upper()\n",
    "  count = 0\n",
    "  for op in ['=', '<>', '!=', '<=', '>=', '<', '>']:\n",
    "    count += len(re.findall(re.escape(op), sql))\n",
    "  for op in ['AND', 'OR', 'NOT', 'LIKE', 'ILIKE', 'IN', 'BETWEEN', 'EXISTS']:\n",
    "    count += len(re.findall(rf'\\b{op}\\b', sql_upper))\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0298e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlshare_complexity(sql):\n",
    "  tokens = tokenize(sql)\n",
    "  structure = {\n",
    "    'table_count': count_tables(sql),\n",
    "    'column_count': count_columns(tokens),\n",
    "    'operator_count': divide_tokens(tokens)['total_operators'],\n",
    "    'character_length': len(sql),\n",
    "    'expression_count': count_expressions(sql),\n",
    "  }\n",
    "  return round(0.12*structure.get('table_count', 0)+0.08*structure.get('column_count', 0)+0.002*structure.get('character_length', 0)+0.20*structure.get('operator_count', 0)+0.15*structure.get('expression_count', 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9881b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_complexity(metrics):\n",
    "  score = SQL_COMMAND_WEIGHTS['SELECT']*1+SQL_COMMAND_WEIGHTS['SUBQUERY']*metrics.get('subquery_count', 0)+SQL_COMMAND_WEIGHTS['WINDOW']*metrics.get('window_function_count', 0)+SQL_COMMAND_WEIGHTS['AGGREGATE']*metrics.get('aggregate_function_count', 0)+SQL_COMMAND_WEIGHTS['CTE']*metrics.get('cte_count', 0)\n",
    "  return round(score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83db6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_query(sql):\n",
    "  if not sql or not sql.strip():\n",
    "    return {}\n",
    "  metrics = {}\n",
    "  metrics.update(size_metrics(sql))\n",
    "  metrics.update(halstead_metrics(sql))\n",
    "  metrics.update(sql_constructs(sql))\n",
    "  metrics.update(cognitive_metrics(sql))\n",
    "  metrics['sqlshare_complexity'] = sqlshare_complexity(sql)\n",
    "  metrics['weighted_complexity'] = weighted_complexity(metrics)\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3805e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(df, col):\n",
    "  metrics_list = []\n",
    "  for sql in df[col]:\n",
    "    if pd.notna(sql):\n",
    "      metrics = evaluate_query(sql)\n",
    "    else:\n",
    "      metrics = {}\n",
    "    metrics_list.append(metrics)\n",
    "  metrics_df = pd.DataFrame(metrics_list)\n",
    "  return pd.concat([df.reset_index(drop=True), metrics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad521e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_dataset(df, 'AXC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a446b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('metrics_dataset.csv', index=False, encoding='utf-8', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25522086",
   "metadata": {},
   "source": [
    "# Abstract Syntax Tree (AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7182af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlglot -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20936758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "from sqlglot import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e105a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ast_features(sql_code):\n",
    "  try:\n",
    "    ast = sqlglot.parse_one(sql_code, dialect='snowflake')\n",
    "  except Exception as e:\n",
    "    print(f\"Parse error: {e}\")\n",
    "    return {\n",
    "      'ast_node_count': 0,\n",
    "      'ast_height': 0,\n",
    "      'ast_branching_factor': 0.0,\n",
    "      'leaf_node_ratio': 0.0\n",
    "    }\n",
    "  features = {\n",
    "    'ast_node_count': len(list(ast.walk()))\n",
    "  }\n",
    "    \n",
    "  def calc_height(node):\n",
    "    if not hasattr(node, 'args') or not node.args:\n",
    "      return 0\n",
    "    return 1 + max((calc_height(child) for child in node.walk() if child is not node), default=0)\n",
    "    \n",
    "  features['ast_height'] = calc_height(ast)\n",
    "    \n",
    "  total_nodes = 0\n",
    "  leaf_nodes = 0\n",
    "  non_leaf_nodes = 0\n",
    "  total_children = 0\n",
    "    \n",
    "  def analyze_tree_structure(node):\n",
    "    nonlocal total_nodes, leaf_nodes, non_leaf_nodes, total_children\n",
    "    total_nodes += 1\n",
    "    children = []\n",
    "    if hasattr(node, 'args'):\n",
    "      for arg_value in node.args.values():\n",
    "        if isinstance(arg_value, list):\n",
    "          children.extend([item for item in arg_value if isinstance(item, exp.Expression)])\n",
    "        elif isinstance(arg_value, exp.Expression):\n",
    "          children.append(arg_value)\n",
    "    num_children = len(children)\n",
    "    if num_children == 0:\n",
    "      leaf_nodes += 1\n",
    "    else:\n",
    "      non_leaf_nodes += 1\n",
    "      total_children += num_children\n",
    "      for child in children:\n",
    "        analyze_tree_structure(child)\n",
    "    \n",
    "  analyze_tree_structure(ast)\n",
    "    \n",
    "  if non_leaf_nodes > 0:\n",
    "    features['ast_branching_factor'] = round(total_children / non_leaf_nodes, 2)\n",
    "  else:\n",
    "    features['ast_branching_factor'] = 0.0\n",
    "  if total_nodes > 0:\n",
    "    features['leaf_node_ratio'] = round(leaf_nodes / total_nodes, 2)\n",
    "  else:\n",
    "    features['leaf_node_ratio'] = 0.0\n",
    "   \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_features = results['AXC'].apply(extract_ast_features)\n",
    "ast_features_df = pd.DataFrame(ast_features.tolist())\n",
    "\n",
    "final_dataset = pd.concat([results, ast_features_df], axis=1)\n",
    "final_dataset.to_csv('metrics_dataset.csv', index=False, encoding='utf-8', sep=';', decimal=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
